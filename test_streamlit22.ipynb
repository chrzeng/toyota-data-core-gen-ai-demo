{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444fb60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6da7bdbf-f7df-42f6-a45e-06fc03581469",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'vertexai'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mvertexai\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mvertexai\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreview\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlanguage_models\u001b[39;00m \u001b[39mimport\u001b[39;00m TextGenerationModel, ChatModel, CodeGenerationModel\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'vertexai'"
     ]
    }
   ],
   "source": [
    "import vertexai\n",
    "from vertexai.preview.language_models import TextGenerationModel, ChatModel, CodeGenerationModel\n",
    "import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "import db_dtypes\n",
    "import base64\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from langchain.vectorstores import Chroma\n",
    "import uuid  \n",
    "import os\n",
    "import time\n",
    "from retry import retry\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "from langchain.prompts.example_selector import SemanticSimilarityExampleSelector\n",
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4fae16-e177-40b5-b4db-f23621bbc146",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_fun(ques):\n",
    "\n",
    "    b = ques\n",
    "\n",
    "    @retry(tries=2)\n",
    "    def predict_large_language_model_sample( project_id: str, model_name: str, temperature: float, max_decode_steps: int, top_p: float, top_k: int, content: str, location: str = \"us-central1\", tuned_model_name: str = \"\",) :\n",
    "\n",
    "        \"\"\"Predict using a Large Language Model.\"\"\"\n",
    "\n",
    "        vertexai.init(project=project_id, location=location)\n",
    "\n",
    "        model = TextGenerationModel.from_pretrained(model_name)\n",
    "\n",
    "        if tuned_model_name:\n",
    "\n",
    "          model = model.get_tuned_model(tuned_model_name)\n",
    "\n",
    "        response = model.predict(content, temperature=temperature, max_output_tokens=max_decode_steps, top_k=top_k, top_p=top_p,)\n",
    "\n",
    "        #print(f\" {response.text}\")\n",
    "\n",
    "        output = response.text\n",
    "       \n",
    "\n",
    "        output = output.replace('sql','')\n",
    "        \n",
    "\n",
    "        output = output.replace('```','')\n",
    "        \n",
    "\n",
    "        return output\n",
    "\n",
    "        \n",
    "\n",
    "    data = predict_large_language_model_sample(\"us-gcp-ame-con-c2aaa-npd-1\", \"text-bison@001\", 0, 962, 0.95, 40, f'''\n",
    "    \n",
    "    your_vision: \" You are a chatbot for toyota vehicle hold inquary\"\n",
    "    your_mission: \" your mission is to provide executable queries from the question {b} \"\n",
    "        \n",
    "    return only the executable sql query for this question, {b} in bigquery? \n",
    "    \n",
    "    CREATE TABLE ds.vehicle (\n",
    "        vin STRING,\n",
    "        modelYear INTEGER,\n",
    "        brand STRING,\n",
    "        series STRING,\n",
    "        modelNumber STRING,\n",
    "        modelPhaseCode STRING,\n",
    "        region STRING,\n",
    "        dealerName STRING,\n",
    "        dealerCode STRING,\n",
    "        LifeCyclePhase STRING,\n",
    "        napCbuIndicator STRING,\n",
    "        fleetIndicator STRING,\n",
    "        vehicleHoldIndicator STRING,\n",
    "        qcHoldIndicator STRING,\n",
    "        financialHoldIndicator STRING,\n",
    "        damageHoldIndicator STRING,\n",
    "        otherHoldIndicator STRING,\n",
    "        qcNumber STRING,\n",
    "        modelDescription STRING,\n",
    "        factoryAccessories STRING,\n",
    "        interiorTrimColorDescription STRING,\n",
    "        interiorColorFabricCode STRING,\n",
    "        interiorTrimDescription STRING,\n",
    "        interiorColorCode STRING,\n",
    "        interiorColorDescription STRING,\n",
    "        exteriorColorName STRING,\n",
    "        exteriorColorCode STRING,\n",
    "        productionLockDate DATE,\n",
    "        dealerInvoiceDate DATE,\n",
    "        buildDate DATE,\n",
    "        plantShortDescription STRING,\n",
    "        plantLongDescription STRING,\n",
    "        damageDescription STRING,\n",
    "        \n",
    "    ) \n",
    "    \n",
    "    Always convert vin, brand, series, modelNumber, region, dealerName to upper case.\n",
    "    \n",
    "    Convert vehicleHoldIndicator, qcHoldIndicator, financialHoldIndicator, otherHoldIndicator to camel.\n",
    "     \n",
    "    To show the trend of vehicle HoldIndicator, always calculate count(vehicleHoldIndicator) and return the query directly.\n",
    "\n",
    "    To calculate deviations, always perform absolute difference between first column name from the question and second column name from the question and always apply STDDEV for the predicted absolute difference and return the query directly.\n",
    "    \n",
    "    Always give a simple alias name to a column if any operation has been performed on that column.\n",
    "    \n",
    "    Configuration details includes FE,CD,CT.\n",
    "    \n",
    "    HoldIndicator includes brand, series, region.\n",
    "    \n",
    "    Always consider model as model number and don't include model year.\n",
    "    \n",
    "    Consider LifeCyclePhase as Life Cycle Phase. \n",
    "    \n",
    "    Consider fleetIndicator as fleet Indicator. \n",
    "    \n",
    "    Consider vehicleHoldIndicator as vehicle hold indicator or vehicle hold. \n",
    "    \n",
    "    Consider financialHoldIndicator as financial hold indicator or financial hold.\n",
    "    \n",
    "    Consider qcHoldIndicator as quality campaign hold indicator or qc hold indicator.\n",
    "    \n",
    "    Consider qc as quality campaign. \n",
    "    \n",
    "    Consider damageHoldIndicator as damage hold indicator or damage hold.\n",
    "    \n",
    "    Consider otherHoldIndicator as other hold indicator or other hold. \n",
    "    \n",
    "    Consider all the business months and don't do any partition.\n",
    "    \n",
    "    Remember that before you answer a question, you must check to see if it compiles with your mission above.\n",
    "\n",
    "    Question : Are there any new series added in the 202305 Business Month \n",
    "    \n",
    "    Answer : SELECT series_name FROM tmna2.tmna2_table WHERE business_month = 202305 AND NOT EXISTS ( SELECT series_name FROM tmna2.tmna2_table WHERE business_month < 202305 ) \n",
    "    \n",
    "    Question : Are there any series discontinued in the 202301 Business Month \n",
    "    \n",
    "    Answer : SELECT series_name FROM tmna2.tmna2_table WHERE business_month < 202301 AND NOT EXISTS ( SELECT series_name FROM tmna2.tmna2_table WHERE business_month >= 202301 )\n",
    "    \n",
    "    Always do AVG(overall_acceptance),AVG(ppr1_acceptance),AVG(ppr2_acceptance),AVG(ppr3_acceptance),AVG(target_acceptance)\n",
    "\n",
    "    Lets think step by step and return only the sql query.\n",
    "          \n",
    "    ''', \"us-central1\")\n",
    "\n",
    "    #dict_sql = str(data.to_dict())\n",
    "\n",
    "    #print(data)\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c988d1a2-3df9-4acd-be16-f5bdf2fa83a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how was the trend for acceptance rate for 1455 model with white color\n",
      "SELECT AVG(overall_acceptance) AS overall_acceptance \n",
      "FROM tmna2.tmna2_table \n",
      "WHERE model_number = 1455 AND configuration_detail = 'White'\n"
     ]
    }
   ],
   "source": [
    "question=\"How many VINs are associated with a quality campaign? \"\n",
    "question=question.lower()\n",
    "if \"business\" in question:\n",
    "    question=question+\" and show the business month\"\n",
    "if \"region\" in question:\n",
    "    question=question+\" and show the region\"\n",
    "if \"series\" in question:\n",
    "    question=question+\" and show the series at first\"\n",
    "if \"brand\" in question:\n",
    "    question=question+\" and show the brand\"\n",
    "if \"how many\" in question:\n",
    "    question=question+\" and show count\"\n",
    "print(question)\n",
    "result = main_fun(question)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fc43e9-f8a6-4812-88a6-214db289ea80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sql_query(sql):\n",
    "    # Create a BigQuery client\n",
    "\n",
    "    client = bigquery.Client()\n",
    "\n",
    "        # Get the list of tables in the dataset\n",
    "\n",
    "    tables = client.list_tables('ds')\n",
    "\n",
    "    results = client.query(sql).to_dataframe()\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a43d8c-08cd-4d1d-8ef4-a6e09f0d5f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result1=run_sql_query(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea7febe-8d62-437a-898a-84cd354e3f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   overall_acceptance\n",
      "0                 NaN\n"
     ]
    }
   ],
   "source": [
    "print(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038fc16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "\n",
    "    \"temperature\": 0,\n",
    "\n",
    "    \"max_output_tokens\": 1024,\n",
    "\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fc459c-28cf-4535-840f-cc76df62e594",
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(tries=2)\n",
    "def table_to_text(question,ans):\n",
    "    model=TextGenerationModel.from_pretrained(model_name='text-bison@001')\n",
    "    instruction = \"\"\" Given a table and a question. \n",
    "    \n",
    "    convert the ans table to a human readable text sentence according to the question.\n",
    "    \n",
    "    \"\"\"\n",
    "    result=model.predict(f'''{instruction},\n",
    "                    question:{question},\n",
    "                     ans:{ans} \n",
    "                     ''',**parameters)\n",
    "    data=result.text\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac95abc-8676-453d-8477-1053a149d76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1                 NaN \n",
      "                     2                 NaN \n",
      "                     3                 NaN  The acceptance rate for 1455 model with white color is NaN.\n"
     ]
    }
   ],
   "source": [
    "sentence1=table_to_text(question,result1)\n",
    "print(sentence1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7519dd92-b918-43c4-9222-d497772de6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result1.to_csv('data.csv')\n",
    "result1.to_csv('ans.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f93ae4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586ac0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import vertexai\n",
    "from streamlit_chat import message\n",
    "\n",
    "#from english2results import get_results\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "vertexai.init(project=\"us-gcp-ame-con-c2aaa-npd-1\", \n",
    "              location=\"us-central1\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea31efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hardcoded UserID\n",
    "USER_ID = \"demo\"\n",
    "\n",
    "st.set_page_config(layout=\"wide\")\n",
    "st.markdown(\"\"\"\n",
    "    <style>\n",
    "        @import url('https://fonts.googleapis.com/css2?family=Roboto&display=swap');\n",
    "    </style>\n",
    "    <div style='text-align: center; font-size: 2.5rem; font-weight: 600; font-family: \"Roboto\"; color: #018BFF; line-height:1; '>Toyota Vehicle Status Bot</div>\n",
    "    <div style='text-align: center; font-size: 1.5rem; font-weight: 300; font-family: \"Roboto\"; color: rgb(179 185 182); line-height:0; '>\n",
    "        Powered by <svg height=\"60\" width=\"120\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><path d=\"M32.377 26.446h-12.52v3.715h8.88c-.44 5.2-4.773 7.432-8.865 7.432a9.76 9.76 0 0 1-9.802-9.891c0-5.624 4.354-9.954 9.814-9.954 4.212 0 6.694 2.685 6.694 2.685l2.6-2.694s-3.34-3.717-9.43-3.717c-7.755 0-13.754 6.545-13.754 13.614 0 6.927 5.643 13.682 13.95 13.682 7.307 0 12.656-5.006 12.656-12.408 0-1.562-.227-2.464-.227-2.464z\" fill=\"#4885ed\"/><use xlink:href=\"#A\" fill=\"#db3236\"/><use xlink:href=\"#A\" x=\"19.181\" fill=\"#f4c20d\"/><path d=\"M80.628 23.765c-4.716 0-8.422 4.13-8.422 8.766 0 5.28 4.297 8.782 8.34 8.782 2.5 0 3.83-.993 4.8-2.132v1.73c0 3.027-1.838 4.84-4.612 4.84-2.68 0-4.024-1.993-4.5-3.123l-3.372 1.4c1.196 2.53 3.604 5.167 7.9 5.167 4.7 0 8.262-2.953 8.262-9.147V24.292H85.36v1.486c-1.13-1.22-2.678-2.013-4.73-2.013zm.34 3.44c2.312 0 4.686 1.974 4.686 5.345 0 3.427-2.37 5.315-4.737 5.315-2.514 0-4.853-2.04-4.853-5.283 0-3.368 2.43-5.378 4.904-5.378z\" fill=\"#4885ed\"/><path d=\"M105.4 23.744c-4.448 0-8.183 3.54-8.183 8.76 0 5.526 4.163 8.803 8.6 8.803 3.712 0 6-2.03 7.35-3.85l-3.033-2.018c-.787 1.22-2.103 2.415-4.298 2.415-2.466 0-3.6-1.35-4.303-2.66l11.763-4.88-.6-1.43c-1.136-2.8-3.787-5.14-7.295-5.14zm.153 3.374c1.603 0 2.756.852 3.246 1.874l-7.856 3.283c-.34-2.542 2.07-5.157 4.6-5.157z\" fill=\"#db3236\"/><path d=\"M91.6 40.787h3.864V14.93H91.6z\" fill=\"#3cba54\"/><defs><path id=\"A\" d=\"M42.634 23.755c-5.138 0-8.82 4.017-8.82 8.7 0 4.754 3.57 8.845 8.88 8.845 4.806 0 8.743-3.673 8.743-8.743 0-5.8-4.58-8.803-8.803-8.803zm.05 3.446c2.526 0 4.92 2.043 4.92 5.334 0 3.22-2.384 5.322-4.932 5.322-2.8 0-5-2.242-5-5.348 0-3.04 2.18-5.308 5.02-5.308z\"/></defs></svg> GenAI\n",
    "    </div>\n",
    "\"\"\", unsafe_allow_html=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8807352f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_context(prompt, context_data='generated'):\n",
    "    context = []\n",
    "    # If any history exists\n",
    "    if st.session_state['generated']:\n",
    "        # Add the last three exchanges\n",
    "        size = len(st.session_state['generated'])\n",
    "        for i in range(max(size-3, 0), size):\n",
    "            context.append(st.session_state['user_input'][i])\n",
    "            if len(st.session_state[context_data]) > i:\n",
    "                context.append(st.session_state[context_data][i])\n",
    "    # Add the latest user prompt\n",
    "    context.append(str(prompt))\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf77b557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generated natural language\n",
    "if 'generated' not in st.session_state:\n",
    "    st.session_state['generated'] = []\n",
    "# Neo4j database results\n",
    "if 'database_results' not in st.session_state:\n",
    "    st.session_state['database_results'] = []\n",
    "# User input\n",
    "if 'user_input' not in st.session_state:\n",
    "    st.session_state['user_input'] = []\n",
    "# Generated Cypher statements\n",
    "#if 'cypher' not in st.session_state:\n",
    "#    st.session_state['cypher'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ebb56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text():\n",
    "    input_text = st.text_input(\n",
    "        \"How can I help you?\", \"\", key=\"input\")\n",
    "    return input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94ee974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns\n",
    "col1, col2 = st.columns([2, 1])\n",
    "\n",
    "with col2:\n",
    "    another_placeholder = st.empty()\n",
    "with col1:\n",
    "    placeholder = st.empty()\n",
    "user_input = get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fdd09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if user_input:\n",
    "    start = timer()\n",
    "    #results = get_results(generate_context(user_input, 'database_results'))\n",
    "    results = table_to_text(question,result1)\n",
    "    try:\n",
    "        #cypher_step = results['intermediate_steps']\n",
    "        #print('Total Time : {}'.format(timer() - start))\n",
    "        #if len(cypher_step) > 0 and 'query' in cypher_step[0]:\n",
    "        #    st.session_state.cypher.append(cypher_step[0]['query'])\n",
    "        #else :\n",
    "        #    st.session_state.cypher.append('')\n",
    "        \n",
    "        #if len(cypher_step) > 1 and 'context' in cypher_step[1] and len(cypher_step[1]['context']) > 0:\n",
    "        #    st.session_state.database_results.append(cypher_step[1]['context'][0])\n",
    "        #else:\n",
    "        \n",
    "        st.session_state.database_results.append('')\n",
    "        \n",
    "        st.session_state.user_input.append(user_input)\n",
    "        st.session_state.generated.append(results['result'])\n",
    "        \n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        st.session_state.user_input.append(user_input)\n",
    "        st.session_state.generated.append(\"Could not generate result due to an error or LLM Quota exceeded\")\n",
    "        #st.session_state.cypher.append(\"\")\n",
    "        #st.session_state.database_results.append('{}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2621cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Message placeholder\n",
    "with placeholder.container():\n",
    "    if st.session_state['generated']:\n",
    "        size = len(st.session_state['generated'])\n",
    "        # Display only the last three exchanges\n",
    "        for i in range(max(size-3, 0), size):\n",
    "            message(st.session_state['user_input'][i],\n",
    "                    is_user=True, key=str(i) + '_user')\n",
    "            message(st.session_state[\"generated\"][i], key=str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a0301c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generated Cypher statements\n",
    "with another_placeholder.container():\n",
    "    if st.session_state['database_results']:\n",
    "        st.text_area(\"Latest generated Query statement\",\n",
    "                     st.session_state['database_results'][-1], height=240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06541e6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5e8bea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7413fa-d44d-4eea-b556-a009858fb18c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
